---
title: "EDA"
author: "Hope Hennessy"
date: "2025-09-17"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(corrplot)
library(lubridate)
library(gridExtra)
```


```{r}
data <- read.csv("~/University/MSc Data Science/STA5073Z_DS Industry/DS-Industry/scotland_avalanche_forecasts_2009_2025.csv", header = TRUE)
```

```{r, eval=FALSE}
head(data)
dim(data)
str(data)
table(data$FAH) # target variable levels
summary(data)
```


# Cleaning

```{r}
# Only keep rows where the target variable FAH is not missing (-109 rows)
data <- data %>% filter(!is.na(FAH) & FAH != "")

# Convert categorical target variable to numeric 
data$FAH <- as.integer(factor(x = data$FAH, levels = c("Low", "Moderate", "Considerable -", "Considerable +", "High"))) - 1
data$Precip.Code <- as.integer(factor(data$Precip.Code)) - 1
data$Area <- as.integer(factor(data$Area)) - 1   # 6 areas

# Create a year variable for date & Month
# Don't have any data for July, Aug and Sept (summer months) 
# Don't know if a month variable will be important? Should i make those months values be 0?
data <- data %>% mutate(Year = year(Date), Month = month(Date))
table(data$Month)

# Remove unnecessary columns
data <- data %>% select(-OSgrid, -OAH, -Obs, -Location, -Date)

```

# Missing data summary

```{r}
missing_summary <- data %>%
  summarise_all(~sum(is.na(.))) %>%
  pivot_longer(everything(), names_to = "Variable", values_to = "Missing_Count") %>%
  mutate(Missing_Percent = round(Missing_Count / nrow(data) * 100, 1)) %>%
  arrange(desc(Missing_Count))
missing_summary

```

# Cleaning dataset from errors 

```{r}
data_cleaned <- data %>%
  mutate(
    Alt = ifelse(Alt < 0 | Alt > 1345, NA_real_, Alt),
    Aspect = ifelse(Aspect < 0 | Aspect > 360, NA_real_, Aspect),
    Incline = ifelse(Incline < 0 | Incline > 90, NA_real_, Incline),
    Wind.Speed = ifelse(Wind.Speed < 0 | Wind.Speed > 176, NA_real_, Wind.Speed),
    Cloud = ifelse(Cloud < 0 | Cloud > 100, NA_real_, Cloud),
    Total.Snow.Depth = ifelse(Total.Snow.Depth < 0 | Total.Snow.Depth > 1500, NA_real_, Total.Snow.Depth),
    Summit.Wind.Speed = ifelse(Summit.Wind.Speed < 0 | Summit.Wind.Speed > 176, NA_real_, Summit.Wind.Speed),
    Foot.Pen = ifelse(Foot.Pen < 0 | Foot.Pen > 100, NA_real_, Foot.Pen),
    Wind.Dir = ifelse(Wind.Dir < 0 | Wind.Dir > 360, NA_real_, Wind.Dir),
    Summit.Wind.Dir = ifelse(Summit.Wind.Dir < 0 | Summit.Wind.Dir > 360, NA_real_, Summit.Wind.Dir),
    Snow.Temp = ifelse(Snow.Temp > 0.5, NA_real_, Snow.Temp),
    Max.Temp.Grad = ifelse(Max.Temp.Grad < 0 | Max.Temp.Grad > 2.5, NA_real_, Max.Temp.Grad))

```


```{r}
# Convert circular variables into two features using sine and cosine transformations
data_cleaned <- data_cleaned %>% 
  mutate(Aspect_sin = sin(Aspect * pi / 180), Aspect_cos = cos(Aspect * pi / 180)) %>% 
  mutate(WindDir_sin = sin(Wind.Dir * pi / 180), WindDir_cos = cos(Wind.Dir * pi / 180)) %>%
  mutate(SummitWindDir_sin = sin(Summit.Wind.Dir * pi / 180), SummitWindDir_cos = cos(Summit.Wind.Dir * pi / 180)) %>%
  select(-Wind.Dir, -Aspect, -Summit.Wind.Dir)

```


```{r}
# Remove variables with high percentage of missing values or  those that don't make sense
data_cleaned <- data_cleaned %>%
  select(-Ski.Pen, -AV.Cat, -Crystals, -Wetness, -Year, -Snow.Index, -Insolation, -No.Settle)
names(data_cleaned)
```


Removing observations with a plausible Total.Snow.Depth & Foot.Pen values, however, Foot.Pen > Total.Snow.Depth, which is impossible:

```{r}
data_cleaned <- data_cleaned %>%
  filter(Foot.Pen < Total.Snow.Depth)
```


## Missing data summary on cleaned dataset

```{r}
missing_summary <- data_cleaned %>%
  summarise_all(~sum(is.na(.))) %>%
  pivot_longer(everything(), names_to = "Variable", values_to = "Missing_Count") %>%
  mutate(Missing_Percent = round(Missing_Count / nrow(data) * 100, 1)) %>%
  arrange(desc(Missing_Count))
missing_summary

```


# I kept longatiude and latitude in. They must be scaled

E.g.

```{r}
data_cleaned <- data_cleaned %>%
  mutate(
    longitude_scaled = scale(longitude),
    latitude_scaled = scale(latitude)) %>%
  select(-longitude, -latitude)  

```





# Data & Methods

The dataset used in this study consists of daily avalanche forecasts for six forecasting regions across Scotland (Creag Meagaidh, Glencoe, Lochaber, Northern Cairngorms, Southern Cairngorms, and Torridon), collected by the Scottish Avalanche Information Service (SAIS) between 2009 and 2025. It contains 10,671 observations and 34 variables including weather conditions, topography, snowpack properties, and avalanche hazard levels.

The target variable for this project is the Forecast Avalanche Hazard (FAH), a categorical variable with five ordered levels: Low, Moderate, Considerable -, Considerable +, and High. 


## Data Cleaning and Preprocessing


The raw dataset underwent extensive cleaning prior to analysis. Initially, rows with missing FAH values (109 rows) were removed, and FAH levels were replaced with a numerical representation from 0 to 4 for compatibility with the neural network software. Other categorical variables, such as precipitation type and forecast region, were similarly transformed into numerical formats. The Date column was transformed into Month to capture seasonal effects.

Variables unrelated to forecasting or with high missingness (more than 20%), frequent errors, limited predictive value, or poorly defined measures were excluded, resulting in a set of well-defined predictors most relevant for forecasting. 

Range checks were applied to remove physically impossible or implausible values based physical limits and regional context.

For example, altitude was limited to 0–1,345 m, the height of Ben Nevis (*...*), and wind speeds to 176 mph, reflecting the highest recorded gust in the Highlands (*...*).

Slope inclines were restricted to 0–90°, and wind directions were constrained to 0–360°. Cloud cover was limited to 0–100%, total snow depth to 0–1,500 cm (with unrealistic spikes removed), and foot penetration depth to 100 cm. Snow temperatures above 0.5 °C were flagged as implausible, since snow begins melting at 0 °C, and maximum temperature gradients were limited to below 25 °C per 10 cm (*...*). Observations where foot penetration exceeded total snow depth were also removed.

Circular variables such as wind direction and aspect were transformed into sine and cosine components.

Exploratory data analysis (EDA) was then performed to assess variable distributions, relationships with FAH, multicollinearity, and seasonal and geographic trends using correlation heatmaps, histograms, scatterplots, and boxplots.






























