{
  "hash": "f51f77782adf9e93a19fe3511a2cb3c0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"\"\nformat: html\nexecute:\n  echo: true\n  warning: false\n  message: false\n---\n\n\n::: {.cell}\n\n:::\n\n\n\n\n## 2. Data and Methods {#sec-Data_and_Methods}\n\nThe dataset used in this study consists of daily avalanche forecasts for six forecasting regions across Scotland (Creag Meagaidh, Glencoe, Lochaber, Northern Cairngorms, Southern Cairngorms, and Torridon), collected by the Scottish Avalanche Information Service (SAIS) between 2009 and 2025. It contains 10,671 observations and 34 variables including weather conditions, topography, snowpack properties, and avalanche hazard levels.\n\nThe target variable for this project is the Forecast Avalanche Hazard (FAH), a categorical variable with five ordered levels: Low, Moderate, Considerable -, Considerable +, and High.\n\nData Cleaning and Preprocessing was done to remove observations that did not make logical sense, transform the data where needed and remove necessary variable. Furthermore, Exploratory Data Analysis (EDA) was then performed to assess variable distributions and perform imputation, outlier handling and scaling of data.\n\n### 2.1 Data Cleaning and Preprocessing\n\nThe raw dataset underwent extensive cleaning prior to analysis. Initially, rows with missing FAH values (109 rows) were removed, and FAH levels were replaced with a numerical representation from 0 to 4 for compatibility with the neural network software. Other categorical variables, such as precipitation type and forecast region, were similarly transformed into numerical formats. The Date column was transformed into Month to capture seasonal effects.\n\nVariables unrelated to forecasting or with high missingness (more than 20%), frequent errors, limited predictive value, or poorly defined measures were excluded, resulting in a set of well-defined predictors most relevant for forecasting.\n\nRange checks were applied to remove physically impossible or implausible values based physical limits and regional context.\n\nFor example, altitude was limited to 0–1,345 m, the height of Ben Nevis (*...*), and wind speeds to 176 mph, reflecting the highest recorded gust in the Highlands (*...*).\n\nSlope inclines were restricted to 0–90°, and wind directions were constrained to 0–360°. Cloud cover was limited to 0–100%, total snow depth to 0–1,500 cm (with unrealistic spikes removed), and foot penetration depth to 100 cm. Snow temperatures above 0.5 °C were flagged as implausible, since snow begins melting at 0 °C, and maximum temperature gradients were limited to below 25 °C per 10 cm (*...*). Observations where foot penetration exceeded total snow depth were also removed.\n\nCircular variables such as wind direction and aspect were transformed into sine and cosine components.\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   1    2    3    4    5    7   11   12 \n2721 2538 2597 1028   54    1   27 1596 \n```\n\n\n:::\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 31 × 3\n   Variable          Missing_Count Missing_Percent\n   <chr>                     <int>           <dbl>\n 1 AV.Cat                     2468            23.4\n 2 Ski.Pen                    2375            22.5\n 3 Summit.Wind.Dir            1305            12.4\n 4 Crystals                    972             9.2\n 5 Summit.Wind.Speed           901             8.5\n 6 Summit.Air.Temp             746             7.1\n 7 Snow.Index                  737             7  \n 8 Max.Temp.Grad               642             6.1\n 9 Max.Hardness.Grad           562             5.3\n10 Wetness                     555             5.3\n# ℹ 21 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 26 × 3\n   Variable          Missing_Count Missing_Percent\n   <chr>                     <int>           <dbl>\n 1 SummitWindDir_sin          1489            14.2\n 2 SummitWindDir_cos          1489            14.2\n 3 Max.Temp.Grad              1350            12.9\n 4 Summit.Wind.Speed          1166            11.1\n 5 Summit.Air.Temp             745             7.1\n 6 Snow.Temp                   632             6  \n 7 Max.Hardness.Grad           557             5.3\n 8 Aspect_sin                  320             3.1\n 9 Aspect_cos                  320             3.1\n10 Total.Snow.Depth            190             1.8\n# ℹ 16 more rows\n```\n\n\n:::\n:::\n\n\n\n### 2.2 Predictor Sets\n\n\n\n::: {.cell}\n\n:::\n\n\n\nThe data was split into three predictor sets; pred1, pred2, and pred3, where each predictor set represents different types of information relating to snow and avalanche conditions. Furthermore, predictor set 1 represents the location data such as the area, exact location coordinates, and how steep the slope is etc. Predictor set 2 represents the air conditions such as air temperature, cloud cover, and wind speed etc. Lastly, predictors 3 represents the snow conditions such as how deep the snow is, the temperature of the snow at different layers and foot penetration. All three predictor sets essentially contribute to determining how the events have affected the snowfall. In addition, the month variable does not fit in any predictor set, but rather adds seasonal context since snow behaviour differs throughout the year. The predictor sets were separated into the following sets:\n\nPredictor Set 1: Area, longitude, latitude, Alt, Incline, Aspect_sin, and Aspect_cos\n\nPredictor Set 2: Air.Temp, Wind.Speed, Cloud, Precip.Code, Drift, Summit.Air.Temp, Summit.Wind.Speed, WindDir_sin, WindDir_cos, SummitWindDir_sin, and SummitWindDir_cos\n\nPredictor Set 3: Total.Snow.Depth, Foot.Pen, Rain.at.900, Max.Temp.Grad, Max.Hardness.Grad, and Snow.Temp\n\nOther Variables: Month\n\n### 2.3 Imputation\n\nMultiple Imputation by Chained Equations (MICE) handles missing data that creates multiple versions of a dataset rather than selecting the first best guessed value. The MICE function ran under the assumption of Missing at Random (MAR), which means that it was assumed that the probability of a value being missing depends on the observed values in the dataset, but are independent of the unobserved values (Kenward & Carpenter, 2007).\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Data_and_Methods_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      FAH Area longitude latitude Alt Cloud Air.Temp Incline Wind.Speed\n10069   1    1         1        1   1     1        1       1          1\n314     1    1         1        1   1     1        1       1          1\n41      1    1         1        1   1     1        1       1          0\n12      1    1         1        1   1     1        1       0          1\n3       1    1         1        1   1     1        1       0          1\n5       1    1         1        1   1     1        0       1          1\n3       1    1         1        1   1     1        0       1          0\n1       1    1         1        1   1     1        0       0          0\n1       1    1         1        1   1     1        0       0          0\n6       1    1         1        1   1     0        1       1          1\n1       1    1         1        1   1     0        1       1          0\n1       1    1         1        1   1     0        1       0          0\n3       1    1         1        1   1     0        0       1          0\n8       1    1         1        1   1     0        0       0          0\n6       1    1         1        1   0     1        1       1          1\n1       1    1         1        1   0     1        1       1          1\n1       1    1         1        1   0     1        1       0          1\n        0    0         0        0   8    19       21      27         59\n      Aspect_sin Aspect_cos    \n10069          1          1   0\n314            0          0   2\n41             1          1   1\n12             1          1   1\n3              0          0   3\n5              1          1   1\n3              1          1   2\n1              1          1   3\n1              0          0   5\n6              1          1   1\n1              1          1   2\n1              1          1   3\n3              1          1   3\n8              1          1   4\n6              1          1   1\n1              0          0   3\n1              0          0   4\n             320        320 774\n```\n\n\n:::\n:::\n\n\n\nThe figure above shows the pattern of missing values for a subset of 10 variables, where blue represents no missing values and red represents missing values present. It can be seen that the sum of missing values for the 10 variables was 774 values, and it can be seen that aspect_sin and aspect_cos have the highest number of missing values (320 values) among these 10 variables. Furthermore, wind.speed, incline, air.temp and cloud have the next highest missing values of 59, 27, 21 and 19 respectively.\n\nIn addition, it was seen that variables like area, latitude, longitude and alt have no missing values, which shows that they are reliable predictors for the missing values in other varaiables.\n\n\n\n::: {.cell}\n\n:::\n\n\n\nMICE was run with five iterations creating five slightly different datasets and Predictive Mean Matching (PMM) was used, which uses the information in the dataset to predict what the missing values would most likely be. In addition, all variables that were in the cleaned dataset which contained missing values were selected for imputation, as the highest percentage of missing data was 14.2%, so there were enough observed variables to predict the unobserved variables well.\n\nIn addition, after running the MICE imputation, the density plots were analysed to determine if the variables were imputed well or not, with imputed values represented by the red line and observed values represented by the blue line. Imputed values should not change the distribution of a variable (Molenberghs & Kenward, 2006), thus, if the imputed variables shows a different distribution to the observed variables, the variable was removed from the dataset.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Data_and_Methods_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\nThe figure above displays a stripplot from the MICE imputation, which shows the distribution across all variables and the five different imputation sets of observed values represented by blue and the imputed values represented by red. It can be seen that the red and blue dots overlap well and follow similar distributions in multiple variables which shows that the imputation worked well.\n\nHowever, variables such as Alt, Air.Temp, and Incline show that imputed values do not follow the same distribution as the observed values as the red dots do not overlap well and indicates that the data failed to impute well under the MAR assumption.\n\nThe density plots for the variables in question were plotted as well as the density plot of Max.Hardness.Grad which imputed well as a comparison,\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Data_and_Methods_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\nIt can be seen from the figure above that the imputed values in red do not follow the observed values in blue for Alt, Incline, and Air.Temp. However, comparing it to a well imputed variable like Max.Hardness.Grad, it can be seen that the imputed values follows the observed values distribution closely. This exercise was done for each of the imputed variable, however, just the variables that did not impute well and one variable that did impute well was shown in the final report.\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\nThe variable that did not impute well was removed from the dataset, and the new dataset was refitted using MICE which ensured that the imputations better satisfied the MAR assumption and produced reliable results.\n\n### 2.4 Outlier Handling\n\nOutlier Capping or Winsorization is a method that handles outliers by converting the extreme high values to the value of the highest data point that is not considered an outlier (Cervinski *et al.*, 2023). This method was used on the imputed dataset to account for any values that were extreme to ensure that the distribution is not skewed.\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"longitude - Outliers capped: 207\"\n[1] \"latitude - Outliers capped: 208\"\n[1] \"Wind.Speed - Outliers capped: 45\"\n[1] \"Summit.Air.Temp - Outliers capped: 207\"\n[1] \"Summit.Wind.Speed - Outliers capped: 95\"\n[1] \"Total.Snow.Depth - Outliers capped: 103\"\n[1] \"Foot.Pen - Outliers capped: 68\"\n[1] \"Max.Temp.Grad - Outliers capped: 93\"\n[1] \"Max.Hardness.Grad - Outliers capped: 48\"\n[1] \"Snow.Temp - Outliers capped: 135\"\n```\n\n\n:::\n:::\n\n\n\nFor each variable in the dataset, the 1st and 99th percentile was calculated to address the extreme values, preserving 98% of the data. If a value fell below the 1st percentile, it was capped to the 1st percentile value, furthermore, if a value fell above the 99th percentile, it was capped to the 99th percentile value.\n\nIn addition, outlier handling was intentionally done after imputation, in the event that MICE generated a value that fell outside of the realistic range of values in the original dataset, considering that data cleaning had already taken place.\n\nFurthermore, it was seen that the need to cap outliers was needed as multiple variables had around \\~1% of its data capped, which shows that the data contained extreme values either in the original dataset or from imputation.\n\n### 2.5 Correlation Analysis\n\nA correlation analysis was performed to examine the patterns in the variables and assess potential multicollinearity effects.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Data_and_Methods_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\nIt can be seen from the figure above that correlation between variables exist as the dark blue squares represent strong positive correlations and the dark red squares represent strong negative correlations. The variables from predictor set 1 are represented by dark blue squares, indicating strong positive correlations between the variables. Moreover, FAH has moderate correlations with the variables as the colour range are in the lighter section of the colour scale.\n\nFurthermore, it is important to note that the white squares represent independent variables (correlation of 0), and it can be seen that there are multiple variables such as Aspect_cos and Area have white squares which indicates that multicollinearity is not excessive.\n\nLastly, it can be seen that variables with similar correlation patterns have grouped together creating visible blocks of related variables, which confirms the predictor set groupings capture different types of information.\n\n\n\n::: {.cell}\n\n:::\n\n\n\n### 2.6 Data Scaling\n\nScaling was performed to ensure that variables with different units and scales contributed equally to the model and variables with larger numeric values did not dominate the model.\n\n\n\n::: {.cell}\n\n:::\n\n\n\nThe data was split using a 70/30 split, which was stratified using FAH to ensure that both the training and testing sets follow a similar distribution of the target variable, FAH. Thereafter, the numeric values from the training dataset were used to calculate the mean and standard deviation of each variable using the preProcess() function and was then applied to both the training and test sets using the predict() function. Furthermore, this approach prevents data leakage which occurs when information from the test set goes into the training set.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}