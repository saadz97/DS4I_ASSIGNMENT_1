{"title":"Final EDA","markdown":{"yaml":{"title":"Final EDA","format":"html","editor":"visual"},"headingText":"Only keep rows where the target variable FAH is not missing (-109 rows)","containsRefs":false,"markdown":"\n\n```{r}\nknitr::opts_chunk$set(echo = TRUE)\n\nlibrary(tidyverse)\nlibrary(corrplot)\nlibrary(lubridate)\nlibrary(gridExtra)\nlibrary(VIM)\nlibrary(mice)\nlibrary(caret)\nlibrary(ggplot2)\n```\n\n```{r}\ndata <- read.csv(\"scotland_avalanche_forecasts_2009_2025.csv\", header = TRUE)\n```\n\n```{r}\nhead(data)\ndim(data)\nstr(data)\ntable(data$FAH) # target variable levels\nsummary(data)\n```\n\nCleaning\n\n```{r}\ndata <- data %>% filter(!is.na(FAH) & FAH != \"\")\n\n# Convert categorical target variable to numeric \ndata$FAH <- as.integer(factor(x = data$FAH, levels = c(\"Low\", \"Moderate\", \"Considerable -\", \"Considerable +\", \"High\"))) - 1\ndata$Precip.Code <- as.integer(factor(data$Precip.Code)) - 1\ndata$Area <- as.integer(factor(data$Area)) - 1   # 6 areas\n\n# Create a year variable for date & Month\n# Don't have any data for July, Aug and Sept (summer months) \n# Don't know if a month variable will be important? Should i make those months values be 0?\ndata <- data %>% mutate(Year = year(Date), Month = month(Date))\ntable(data$Month)\n\n# Remove unnecessary columns\ndata <- data %>% select(-OSgrid, -OAH, -Obs, -Location, -Date)\n```\n\nMissing Data\n\n```{r}\nmissing_summary <- data %>%\n  summarise_all(~sum(is.na(.))) %>%\n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Missing_Count\") %>%\n  mutate(Missing_Percent = round(Missing_Count / nrow(data) * 100, 1)) %>%\n  arrange(desc(Missing_Count))\nmissing_summary\n```\n\nCleaning dataset from errors\n\n```{r}\ndata_cleaned <- data %>%\n  mutate(\n    Alt = ifelse(Alt < 0 | Alt > 1345, NA_real_, Alt),\n    Aspect = ifelse(Aspect < 0 | Aspect > 360, NA_real_, Aspect),\n    Incline = ifelse(Incline < 0 | Incline > 90, NA_real_, Incline),\n    Wind.Speed = ifelse(Wind.Speed < 0 | Wind.Speed > 176, NA_real_, Wind.Speed),\n    Cloud = ifelse(Cloud < 0 | Cloud > 100, NA_real_, Cloud),\n    Total.Snow.Depth = ifelse(Total.Snow.Depth < 0 | Total.Snow.Depth > 1500, NA_real_, Total.Snow.Depth),\n    Summit.Wind.Speed = ifelse(Summit.Wind.Speed < 0 | Summit.Wind.Speed > 176, NA_real_, Summit.Wind.Speed),\n    Foot.Pen = ifelse(Foot.Pen < 0 | Foot.Pen > 100, NA_real_, Foot.Pen),\n    Wind.Dir = ifelse(Wind.Dir < 0 | Wind.Dir > 360, NA_real_, Wind.Dir),\n    Summit.Wind.Dir = ifelse(Summit.Wind.Dir < 0 | Summit.Wind.Dir > 360, NA_real_, Summit.Wind.Dir),\n    Snow.Temp = ifelse(Snow.Temp > 0.5, NA_real_, Snow.Temp),\n    Max.Temp.Grad = ifelse(Max.Temp.Grad < 0 | Max.Temp.Grad > 2.5, NA_real_, Max.Temp.Grad))\n```\n\n```{r}\n# Convert circular variables into two features using sine and cosine transformations\ndata_cleaned <- data_cleaned %>% \n  mutate(Aspect_sin = sin(Aspect * pi / 180), Aspect_cos = cos(Aspect * pi / 180)) %>% \n  mutate(WindDir_sin = sin(Wind.Dir * pi / 180), WindDir_cos = cos(Wind.Dir * pi / 180)) %>%\n  mutate(SummitWindDir_sin = sin(Summit.Wind.Dir * pi / 180), SummitWindDir_cos = cos(Summit.Wind.Dir * pi / 180)) %>%\n  select(-Wind.Dir, -Aspect, -Summit.Wind.Dir)\n\n```\n\n```{r}\n# Remove variables with high percentage of missing values or  those that don't make sense\n\ndata_cleaned <- data_cleaned %>%\n  select(-Ski.Pen, -AV.Cat, -Crystals, -Wetness, -Year, -Snow.Index, -Insolation, -No.Settle)\nnames(data_cleaned)\n\ndim(data_cleaned)\n```\n\nRemoving observations with a plausible Total.Snow.Depth & Foot.Pen values, however, Foot.Pen \\> Total.Snow.Depth, which is impossible:\n\n```{r}\ndata_cleaned <- data_cleaned %>%\n  filter(is.na(Foot.Pen) | is.na(Total.Snow.Depth) | Foot.Pen <= Total.Snow.Depth)\n```\n\nMissing data summary on cleaned dataset\n\n```{r}\nmissing_summary <- data_cleaned %>%\n  summarise_all(~sum(is.na(.))) %>%\n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Missing_Count\") %>%\n  mutate(Missing_Percent = round(Missing_Count / nrow(data_cleaned) * 100, 1)) %>%\n  arrange(desc(Missing_Count))\nmissing_summary\n\ndim(data_cleaned)\n```\n\n### **Predictor sets**\n\n```{r}\n\npred_1 <- c(\"Area\", \"longitude\", \"latitude\", \"Alt\", \"Incline\", \"Aspect_sin\", \"Aspect_cos\")\n\npred_2 <- c(\"Air.Temp\", \"Wind.Speed\", \"Cloud\", \"Precip.Code\", \"Drift\",\n           \"Summit.Air.Temp\", \"Summit.Wind.Speed\", \"WindDir_sin\", \"WindDir_cos\", \n           \"SummitWindDir_sin\", \"SummitWindDir_cos\")\n\npred_3 <- c(\"Total.Snow.Depth\", \"Foot.Pen\", \"Rain.at.900\", \"Max.Temp.Grad\", \n           \"Max.Hardness.Grad\", \"Snow.Temp\")\n\nother_vars <- c(\"Month\")\n\nall_pred <- c(pred_1, pred_2, pred_3, other_vars)\n```\n\nThe data was split into three predictor sets; pred1, pred2, and pred3, where each predictor set represents different types of information relating to snow and avalanche conditions. Furthermore, predictor set 1 represents the location data such as the area, exact location coordinates, and how steep the slope is etc. Predictor set 2 represents the air conditions such as air temperature, cloud cover, and wind speed etc. Lastly, predictors 3 represents the snow conditions such as how deep the snow is, the temperature of the snow at different layers and foot penetration. All three predictor sets essentially contribute to determining how the events have affected the snowfall. In addition, the month variable does not fit in any predictor set, but rather adds seasonal context since snow behaviour differs throughout the year.\n\n### **Imputation**\n\nMultiple Imputation by Chained Equations (MICE) handles missing data that creates multiple versions of a dataset rather than selecting the first best guessed value. The MICE function ran under the assumption of Missing at Random (MAR), which means that it was assumed that the probability of a value being missing depends on the observed values in the dataset, but are independent of the unobserved values (Kenward & Carpenter, 2007).\n\n```{r}\n# No variables have more than 50% missing data so impute all missing values.\n\nmd.pattern(data_cleaned[,c(\"FAH\", all_pred[1:min(10, length(all_pred))])], rotate.names = TRUE)\n\n```\n\nThe figure above shows the pattern of missing values for a subset of 10 variables, where blue represents no missing values and red represents missing values present. It can be seen that the sum of missing values for the 10 variables was 774 values, and it can be seen that aspect_sin and aspect_cos have the highest number of missing values (320 values) among these 10 variables. Furthermore, wind.speed, incline, air.temp and cloud have the next highest missing values of 59, 27, 21 and 19 respectively.\n\nIn addition, it was seen that variables like area, latitude, longitude and alt have no missing values, which shows that they are reliable predictors for the missing values in other varaiables.\n\n```{r}\n\nmice_data <- data_cleaned %>%\n  select(FAH, all_of(all_pred))\n\nset.seed(12345)\n\nmice_output <- mice(mice_data, m = 5, method = 'pmm', printFlag = FALSE)\n\ndata_imputed <- complete(mice_output, 1)\n\n\n```\n\nMICE was run with five iterations creating five slightly different datasets and Predictive Mean Matching (PMM) was used, which uses the information in the dataset to predict what the missing values would most likely be. In addition, all variables that were in the cleaned dataset which contained missing values were selected for imputation, as the highest percentage of missing data was 14.2%, so there were enough observed variables to predict the unobserved variables well.\n\nIn addition, after running the MICE imputation, the density plots were analysed to determine if the variables were imputed well or not, with imputed values represented by the red line and observed values represented by the blue line. Imputed values should not change the distribution of a variable (Molenberghs & Kenward, 2006), thus, if the imputed variables shows a different distribution to the observed variables, the variable was removed from the dataset.\n\n```{r}\n\n# Diagnostic Plots\n# Strip plot - shows distribution of imputed values\n\nstripplot(mice_output, pch=20, cex=1.2)\n\n```\n\nThe figure above displays a stripplot from the MICE imputation, which shows the distribution across all variables and the five different imputation sets of observed values represented by blue and the imputed values represented by red. It can be seen that the red and blue dots overlap well and follow similar distributions in multiple variables which shows that the imputation worked well.\n\nHowever, variables such as Alt, Air.Temp, and Incline show that imputed values do not follow the same distribution as the observed values as the red dots do not overlap well and indicates that the data failed to impute well under the MAR assumption.\n\nThe density plots for the variables in question were plotted as well as the density plot of Max.Hardness.Grad which imputed well as a comparison,\n\n```{r}\n\n# densityplot(mice_output, ~ Alt) # bad\n# densityplot(mice_output, ~ Aspect_sin) # maybe\n# densityplot(mice_output, ~ Aspect_cos) \n# densityplot(mice_output, ~ Incline) # bad\n\n# densityplot(mice_output, ~ Air.Temp) # bad\n # densityplot(mice_output, ~ WindDir_sin) # maybe\n# densityplot(mice_output, ~ WindDir_cos) # maybe\n# densityplot(mice_output, ~ Wind.Speed)\n# densityplot(mice_output, ~ Cloud) # maybe\n\n# densityplot(mice_output, ~ Summit.Air.Temp)\n# densityplot(mice_output, ~ SummitWindDir_sin)\n# densityplot(mice_output, ~ SummitWindDir_cos)\n# densityplot(mice_output, ~ Summit.Wind.Speed)\n\n# densityplot(mice_output, ~ Max.Temp.Grad) # maybe\n# densityplot(mice_output, ~ Max.Hardness.Grad) \n# densityplot(mice_output, ~ Snow.Temp) # maybe\n\n\np1 <- densityplot(mice_output, ~ Alt, main = \"Alt\")\np2 <- densityplot(mice_output, ~ Incline, main = \"Incline\")\np3 <- densityplot(mice_output, ~ Air.Temp, main = \"Air.Temp\")\np4 <- densityplot(mice_output, ~ Max.Hardness.Grad, main = \"Max.Hardness.Grad\")\n\ngrid.arrange(p1, p2, p3, p4, ncol = 2)\n\n```\n\nIt can be seen from the figure above that the imputed values in red do not follow the observed values in blue for Alt, Incline, and Air.Temp. However, comparing it to a well imputed variable like Max.Hardness.Grad, it can be seen that the imputed values follows the observed values distribution closely. This exercise was done for each of the imputed variable, however, just the variables that did not impute well and one variable that did impute well was shown in the final report.\n\n```{r}\n\n# Convergence plot\n\n# plot(mice_output, main = \"MICE Convergence - All Variables\")\n\n```\n\n```{r}\n\nbad_vars <- c(\"Alt\", \"Air.Temp\", \"Incline\")\n\nmice_data <- mice_data %>%\n  select(FAH, all_of(setdiff(all_pred, bad_vars)))\n\n# dim(mice_data)\n\nset.seed(12345)\n\nmice_output2 <- mice(mice_data, m = 5, method = 'pmm', printFlag = FALSE)\ndata_imputed2 <- complete(mice_output2, 1)\n```\n\nThe variable that did not impute well was removed from the dataset, and the new dataset was refitted using MICE which ensured that the imputations better satisfied the MAR assumption and produced reliable results.\n\n### Outliers\n\nOutlier Capping or Winsorization is a method that handles outliers by converting the extreme high values to the value of the highest data point that is not considered an outlier (Cervinski *et al.*, 2023). This method was used on the imputed dataset to account for any values that were extreme to ensure that the distribution is not skewed.\n\n```{r}\n\n# Handle outliers by capping them\n\nfor(var in names(data_imputed2)) {\n  if(is.numeric(data_imputed2[[var]])) {\n    \n    x <- data_imputed2[[var]]\n    \n    lower_bound <- quantile(x, 0.01, na.rm = TRUE)\n    upper_bound <- quantile(x, 0.99, na.rm = TRUE)\n    \n    n_outliers <- sum(x < lower_bound | x > upper_bound, na.rm = TRUE)\n    data_imputed2[[var]][x < lower_bound] <- lower_bound\n    data_imputed2[[var]][x > upper_bound] <- upper_bound\n    \n    if(n_outliers > 0) {\n      print(paste(var, \"- Outliers capped:\", n_outliers))\n    }\n  }\n}\n```\n\nFor each variable in the dataset, the 1st and 99th percentile was calculated to address the extreme values, preserving 98% of the data. If a value fell below the 1st percentile, it was capped to the 1st percentile value, furthermore, if a value fell above the 99th percentile, it was capped to the 99th percentile value.\n\nIn addition, outlier handling was intentionally done after imputation, in the event that MICE generated a value that fell outside of the realistic range of values in the original dataset, considering that data cleaning had already taken place.\n\nFurthermore, it was seen that the need to cap outliers was needed as multiple variables had around \\~1% of its data capped, which shows that the data contained extreme values either in the original dataset or from imputation.\n\n### Correlation\n\nA correlation analysis was performed to examine the patterns in the variables and assess potential multicollinearity effects.\n\n```{r}\n\n# Use imputed data (no missing values)\n\ncorr_data <- data_imputed2  \n\ncorr_matrix <- cor(corr_data, use = \"complete.obs\")\n\n# Correlation with FAH\n# fah_corr <- corr_matrix[,\"FAH\"] %>%\n#   as.data.frame() %>%\n#   rownames_to_column(\"Variable\") %>%\n#   rename(Correlation = \".\") %>%\n#   filter(Variable != \"FAH\") %>%\n#   arrange(desc(abs(Correlation)))\n\n# Top 10 correlations with FAH\n# print(head(fah_corr, 10))\n\n# Correlation heatmap\ncorrplot(corr_matrix, method = \"color\", type = \"upper\", \n         order = \"hclust\", tl.cex = 0.7, tl.col = \"black\")\n\n```\n\nIt can be seen from the figure above that correlation between variables exist as the dark blue squares represent strong positive correlations and the dark red squares represent strong negative correlations. The variables from predictor set 1 are represented by dark blue squares, indicating strong positive correlations between the variables. Moreover, FAH has moderate correlations with the variables as the colour range are in the lighter section of the colour scale.\n\nFurthermore, it is important to note that the white squares represent independent variables (correlation of 0), and it can be seen that there are multiple variables such as Aspect_cos and Area have white squares which indicates that multicollinearity is not excessive.\n\nLastly, it can be seen that variables with similar correlation patterns have grouped together creating visible blocks of related variables, which confirms the predictor set groupings capture different types of information.\n\n```{r}\n\n# # FAH Correlation\n# \n# data_imputed2$FAH_factor <- factor(data_imputed2$FAH,\n#                            levels = 0:4,\n#                            labels = c(\"Low\", \"Moderate\", \"Considerable -\", \n#                                      \"Considerable +\", \"High\"))\n# \n# # Predictor 1\n# \n# predictor_1 <- pred_1[pred_1 %in% names(data_imputed2)]\n# \n# data1 <- data_imputed2 %>%\n#   select(FAH_factor, FAH, all_of(predictor_1))\n# \n# corr1 <- cor(data1[,predictor_1], data1$FAH) %>%\n#   as.data.frame() %>%\n#   rownames_to_column(\"Variable\") %>%\n#   rename(FAH_Correlation = \"V1\") %>%\n#   arrange(desc(abs(FAH_Correlation)))\n# \n# # Create boxplots\n# plot1 <- list()\n# for(i in 1:min(4, length(predictor_1))) {\n#   var <- predictor_1[i]\n#   plot1[[i]] <- ggplot(data1, aes(x = factor(FAH_factor), y = .data[[var]])) +\n#     geom_boxplot(fill = \"darkblue\", alpha = 0.7) +\n#     labs(title = paste(var, \"vs FAH\"),\n#          x = \"FAH\", y = var) +\n#     theme_minimal()\n# }\n# \n# do.call(grid.arrange, c(plot1, ncol = 2))\n# \n# # Predictor 2\n# \n# predictor_2 <- pred_2[pred_2 %in% names(data_imputed2)]\n# \n# data2 <- data_imputed2 %>%\n#   select(FAH_factor, FAH, all_of(predictor_2))\n# \n# corr2 <- cor(data2[,predictor_2], data2$FAH) %>%\n#   as.data.frame() %>%\n#   rownames_to_column(\"Variable\") %>%\n#   rename(FAH_Correlation = \"V1\") %>%\n#   arrange(desc(abs(FAH_Correlation)))\n# \n# plot2 <- list()\n# for(i in 1:min(4, length(predictor_2))) {\n#   var <- predictor_2[i]\n#   plot2[[i]] <- ggplot(data2, aes(x = factor(FAH_factor), y = .data[[var]])) +\n#     geom_boxplot(fill = \"darkgreen\", alpha = 0.7) +\n#     labs(title = paste(var, \"vs FAH\"),\n#          x = \"FAH\", y = var) +\n#     theme_minimal()\n# }\n# \n# do.call(grid.arrange, c(plot2, ncol = 2))\n# \n# # Predictor 3\n# \n# predictor_3 <- pred_3[pred_3 %in% names(data_imputed2)]\n# \n# data3 <- data_imputed2 %>%\n#   select(FAH_factor, FAH, all_of(predictor_3))\n# \n# corr3 <- cor(data3[,predictor_3], data3$FAH) %>%\n#   as.data.frame() %>%\n#   rownames_to_column(\"Variable\") %>%\n#   rename(FAH_Correlation = \"V1\") %>%\n#   arrange(desc(abs(FAH_Correlation)))\n# \n# plot3 <- list()\n# for(i in 1:min(4, length(predictor_3))) {\n#   var <- predictor_3[i]\n#   plot3[[i]] <- ggplot(data3, aes(x = factor(FAH_factor), y = .data[[var]])) +\n#     geom_boxplot(fill = \"darkred\", alpha = 0.7) +\n#     labs(title = paste(var, \"vs FAH\"),\n#          x = \"FAH\", y = var) +\n#     theme_minimal()\n# }\n# \n# do.call(grid.arrange, c(plot3, ncol = 2))\n```\n\n### Scaling\n\nScaling was performed to ensure that variables with different units and scales contributed equally to the model and variables with larger numeric values did not dominate the model.\n\n```{r}\n\nset.seed(12345)\n\ntrain_index <- createDataPartition(data_imputed2$FAH, \n                                   p = 0.7, \n                                   list = FALSE)\n\ntrain_data <- data_imputed2[train_index, ]\ntest_data <- data_imputed2[-train_index, ]\n\n# Standardisation\n\nnumeric_vars <- names(data_imputed2)[sapply(data_imputed2, is.numeric)]\nnumeric_vars <- setdiff(numeric_vars, \"FAH\")\n\npreproc_obj <- preProcess(\n  train_data %>% select(all_of(numeric_vars)),\n  method = c(\"center\", \"scale\")  \n)\n\ntrain_scaled <- predict(preproc_obj, train_data)\ntest_scaled <- predict(preproc_obj, test_data)\n\n```\n\nThe data was split using a 70/30 split, which was stratified using FAH to ensure that both the training and testing sets follow a similar distribution of the target variable, FAH. Thereafter, the numeric values from the training dataset were used to calculate the mean and standard deviation of each variable using the preProcess() function and was then applied to both the training and test sets using the predict() function. Furthermore, this approach prevents data leakage which occurs when information from the test set goes into the training set.\n","srcMarkdownNoYaml":"\n\n```{r}\nknitr::opts_chunk$set(echo = TRUE)\n\nlibrary(tidyverse)\nlibrary(corrplot)\nlibrary(lubridate)\nlibrary(gridExtra)\nlibrary(VIM)\nlibrary(mice)\nlibrary(caret)\nlibrary(ggplot2)\n```\n\n```{r}\ndata <- read.csv(\"scotland_avalanche_forecasts_2009_2025.csv\", header = TRUE)\n```\n\n```{r}\nhead(data)\ndim(data)\nstr(data)\ntable(data$FAH) # target variable levels\nsummary(data)\n```\n\nCleaning\n\n```{r}\n# Only keep rows where the target variable FAH is not missing (-109 rows)\ndata <- data %>% filter(!is.na(FAH) & FAH != \"\")\n\n# Convert categorical target variable to numeric \ndata$FAH <- as.integer(factor(x = data$FAH, levels = c(\"Low\", \"Moderate\", \"Considerable -\", \"Considerable +\", \"High\"))) - 1\ndata$Precip.Code <- as.integer(factor(data$Precip.Code)) - 1\ndata$Area <- as.integer(factor(data$Area)) - 1   # 6 areas\n\n# Create a year variable for date & Month\n# Don't have any data for July, Aug and Sept (summer months) \n# Don't know if a month variable will be important? Should i make those months values be 0?\ndata <- data %>% mutate(Year = year(Date), Month = month(Date))\ntable(data$Month)\n\n# Remove unnecessary columns\ndata <- data %>% select(-OSgrid, -OAH, -Obs, -Location, -Date)\n```\n\nMissing Data\n\n```{r}\nmissing_summary <- data %>%\n  summarise_all(~sum(is.na(.))) %>%\n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Missing_Count\") %>%\n  mutate(Missing_Percent = round(Missing_Count / nrow(data) * 100, 1)) %>%\n  arrange(desc(Missing_Count))\nmissing_summary\n```\n\nCleaning dataset from errors\n\n```{r}\ndata_cleaned <- data %>%\n  mutate(\n    Alt = ifelse(Alt < 0 | Alt > 1345, NA_real_, Alt),\n    Aspect = ifelse(Aspect < 0 | Aspect > 360, NA_real_, Aspect),\n    Incline = ifelse(Incline < 0 | Incline > 90, NA_real_, Incline),\n    Wind.Speed = ifelse(Wind.Speed < 0 | Wind.Speed > 176, NA_real_, Wind.Speed),\n    Cloud = ifelse(Cloud < 0 | Cloud > 100, NA_real_, Cloud),\n    Total.Snow.Depth = ifelse(Total.Snow.Depth < 0 | Total.Snow.Depth > 1500, NA_real_, Total.Snow.Depth),\n    Summit.Wind.Speed = ifelse(Summit.Wind.Speed < 0 | Summit.Wind.Speed > 176, NA_real_, Summit.Wind.Speed),\n    Foot.Pen = ifelse(Foot.Pen < 0 | Foot.Pen > 100, NA_real_, Foot.Pen),\n    Wind.Dir = ifelse(Wind.Dir < 0 | Wind.Dir > 360, NA_real_, Wind.Dir),\n    Summit.Wind.Dir = ifelse(Summit.Wind.Dir < 0 | Summit.Wind.Dir > 360, NA_real_, Summit.Wind.Dir),\n    Snow.Temp = ifelse(Snow.Temp > 0.5, NA_real_, Snow.Temp),\n    Max.Temp.Grad = ifelse(Max.Temp.Grad < 0 | Max.Temp.Grad > 2.5, NA_real_, Max.Temp.Grad))\n```\n\n```{r}\n# Convert circular variables into two features using sine and cosine transformations\ndata_cleaned <- data_cleaned %>% \n  mutate(Aspect_sin = sin(Aspect * pi / 180), Aspect_cos = cos(Aspect * pi / 180)) %>% \n  mutate(WindDir_sin = sin(Wind.Dir * pi / 180), WindDir_cos = cos(Wind.Dir * pi / 180)) %>%\n  mutate(SummitWindDir_sin = sin(Summit.Wind.Dir * pi / 180), SummitWindDir_cos = cos(Summit.Wind.Dir * pi / 180)) %>%\n  select(-Wind.Dir, -Aspect, -Summit.Wind.Dir)\n\n```\n\n```{r}\n# Remove variables with high percentage of missing values or  those that don't make sense\n\ndata_cleaned <- data_cleaned %>%\n  select(-Ski.Pen, -AV.Cat, -Crystals, -Wetness, -Year, -Snow.Index, -Insolation, -No.Settle)\nnames(data_cleaned)\n\ndim(data_cleaned)\n```\n\nRemoving observations with a plausible Total.Snow.Depth & Foot.Pen values, however, Foot.Pen \\> Total.Snow.Depth, which is impossible:\n\n```{r}\ndata_cleaned <- data_cleaned %>%\n  filter(is.na(Foot.Pen) | is.na(Total.Snow.Depth) | Foot.Pen <= Total.Snow.Depth)\n```\n\nMissing data summary on cleaned dataset\n\n```{r}\nmissing_summary <- data_cleaned %>%\n  summarise_all(~sum(is.na(.))) %>%\n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Missing_Count\") %>%\n  mutate(Missing_Percent = round(Missing_Count / nrow(data_cleaned) * 100, 1)) %>%\n  arrange(desc(Missing_Count))\nmissing_summary\n\ndim(data_cleaned)\n```\n\n### **Predictor sets**\n\n```{r}\n\npred_1 <- c(\"Area\", \"longitude\", \"latitude\", \"Alt\", \"Incline\", \"Aspect_sin\", \"Aspect_cos\")\n\npred_2 <- c(\"Air.Temp\", \"Wind.Speed\", \"Cloud\", \"Precip.Code\", \"Drift\",\n           \"Summit.Air.Temp\", \"Summit.Wind.Speed\", \"WindDir_sin\", \"WindDir_cos\", \n           \"SummitWindDir_sin\", \"SummitWindDir_cos\")\n\npred_3 <- c(\"Total.Snow.Depth\", \"Foot.Pen\", \"Rain.at.900\", \"Max.Temp.Grad\", \n           \"Max.Hardness.Grad\", \"Snow.Temp\")\n\nother_vars <- c(\"Month\")\n\nall_pred <- c(pred_1, pred_2, pred_3, other_vars)\n```\n\nThe data was split into three predictor sets; pred1, pred2, and pred3, where each predictor set represents different types of information relating to snow and avalanche conditions. Furthermore, predictor set 1 represents the location data such as the area, exact location coordinates, and how steep the slope is etc. Predictor set 2 represents the air conditions such as air temperature, cloud cover, and wind speed etc. Lastly, predictors 3 represents the snow conditions such as how deep the snow is, the temperature of the snow at different layers and foot penetration. All three predictor sets essentially contribute to determining how the events have affected the snowfall. In addition, the month variable does not fit in any predictor set, but rather adds seasonal context since snow behaviour differs throughout the year.\n\n### **Imputation**\n\nMultiple Imputation by Chained Equations (MICE) handles missing data that creates multiple versions of a dataset rather than selecting the first best guessed value. The MICE function ran under the assumption of Missing at Random (MAR), which means that it was assumed that the probability of a value being missing depends on the observed values in the dataset, but are independent of the unobserved values (Kenward & Carpenter, 2007).\n\n```{r}\n# No variables have more than 50% missing data so impute all missing values.\n\nmd.pattern(data_cleaned[,c(\"FAH\", all_pred[1:min(10, length(all_pred))])], rotate.names = TRUE)\n\n```\n\nThe figure above shows the pattern of missing values for a subset of 10 variables, where blue represents no missing values and red represents missing values present. It can be seen that the sum of missing values for the 10 variables was 774 values, and it can be seen that aspect_sin and aspect_cos have the highest number of missing values (320 values) among these 10 variables. Furthermore, wind.speed, incline, air.temp and cloud have the next highest missing values of 59, 27, 21 and 19 respectively.\n\nIn addition, it was seen that variables like area, latitude, longitude and alt have no missing values, which shows that they are reliable predictors for the missing values in other varaiables.\n\n```{r}\n\nmice_data <- data_cleaned %>%\n  select(FAH, all_of(all_pred))\n\nset.seed(12345)\n\nmice_output <- mice(mice_data, m = 5, method = 'pmm', printFlag = FALSE)\n\ndata_imputed <- complete(mice_output, 1)\n\n\n```\n\nMICE was run with five iterations creating five slightly different datasets and Predictive Mean Matching (PMM) was used, which uses the information in the dataset to predict what the missing values would most likely be. In addition, all variables that were in the cleaned dataset which contained missing values were selected for imputation, as the highest percentage of missing data was 14.2%, so there were enough observed variables to predict the unobserved variables well.\n\nIn addition, after running the MICE imputation, the density plots were analysed to determine if the variables were imputed well or not, with imputed values represented by the red line and observed values represented by the blue line. Imputed values should not change the distribution of a variable (Molenberghs & Kenward, 2006), thus, if the imputed variables shows a different distribution to the observed variables, the variable was removed from the dataset.\n\n```{r}\n\n# Diagnostic Plots\n# Strip plot - shows distribution of imputed values\n\nstripplot(mice_output, pch=20, cex=1.2)\n\n```\n\nThe figure above displays a stripplot from the MICE imputation, which shows the distribution across all variables and the five different imputation sets of observed values represented by blue and the imputed values represented by red. It can be seen that the red and blue dots overlap well and follow similar distributions in multiple variables which shows that the imputation worked well.\n\nHowever, variables such as Alt, Air.Temp, and Incline show that imputed values do not follow the same distribution as the observed values as the red dots do not overlap well and indicates that the data failed to impute well under the MAR assumption.\n\nThe density plots for the variables in question were plotted as well as the density plot of Max.Hardness.Grad which imputed well as a comparison,\n\n```{r}\n\n# densityplot(mice_output, ~ Alt) # bad\n# densityplot(mice_output, ~ Aspect_sin) # maybe\n# densityplot(mice_output, ~ Aspect_cos) \n# densityplot(mice_output, ~ Incline) # bad\n\n# densityplot(mice_output, ~ Air.Temp) # bad\n # densityplot(mice_output, ~ WindDir_sin) # maybe\n# densityplot(mice_output, ~ WindDir_cos) # maybe\n# densityplot(mice_output, ~ Wind.Speed)\n# densityplot(mice_output, ~ Cloud) # maybe\n\n# densityplot(mice_output, ~ Summit.Air.Temp)\n# densityplot(mice_output, ~ SummitWindDir_sin)\n# densityplot(mice_output, ~ SummitWindDir_cos)\n# densityplot(mice_output, ~ Summit.Wind.Speed)\n\n# densityplot(mice_output, ~ Max.Temp.Grad) # maybe\n# densityplot(mice_output, ~ Max.Hardness.Grad) \n# densityplot(mice_output, ~ Snow.Temp) # maybe\n\n\np1 <- densityplot(mice_output, ~ Alt, main = \"Alt\")\np2 <- densityplot(mice_output, ~ Incline, main = \"Incline\")\np3 <- densityplot(mice_output, ~ Air.Temp, main = \"Air.Temp\")\np4 <- densityplot(mice_output, ~ Max.Hardness.Grad, main = \"Max.Hardness.Grad\")\n\ngrid.arrange(p1, p2, p3, p4, ncol = 2)\n\n```\n\nIt can be seen from the figure above that the imputed values in red do not follow the observed values in blue for Alt, Incline, and Air.Temp. However, comparing it to a well imputed variable like Max.Hardness.Grad, it can be seen that the imputed values follows the observed values distribution closely. This exercise was done for each of the imputed variable, however, just the variables that did not impute well and one variable that did impute well was shown in the final report.\n\n```{r}\n\n# Convergence plot\n\n# plot(mice_output, main = \"MICE Convergence - All Variables\")\n\n```\n\n```{r}\n\nbad_vars <- c(\"Alt\", \"Air.Temp\", \"Incline\")\n\nmice_data <- mice_data %>%\n  select(FAH, all_of(setdiff(all_pred, bad_vars)))\n\n# dim(mice_data)\n\nset.seed(12345)\n\nmice_output2 <- mice(mice_data, m = 5, method = 'pmm', printFlag = FALSE)\ndata_imputed2 <- complete(mice_output2, 1)\n```\n\nThe variable that did not impute well was removed from the dataset, and the new dataset was refitted using MICE which ensured that the imputations better satisfied the MAR assumption and produced reliable results.\n\n### Outliers\n\nOutlier Capping or Winsorization is a method that handles outliers by converting the extreme high values to the value of the highest data point that is not considered an outlier (Cervinski *et al.*, 2023). This method was used on the imputed dataset to account for any values that were extreme to ensure that the distribution is not skewed.\n\n```{r}\n\n# Handle outliers by capping them\n\nfor(var in names(data_imputed2)) {\n  if(is.numeric(data_imputed2[[var]])) {\n    \n    x <- data_imputed2[[var]]\n    \n    lower_bound <- quantile(x, 0.01, na.rm = TRUE)\n    upper_bound <- quantile(x, 0.99, na.rm = TRUE)\n    \n    n_outliers <- sum(x < lower_bound | x > upper_bound, na.rm = TRUE)\n    data_imputed2[[var]][x < lower_bound] <- lower_bound\n    data_imputed2[[var]][x > upper_bound] <- upper_bound\n    \n    if(n_outliers > 0) {\n      print(paste(var, \"- Outliers capped:\", n_outliers))\n    }\n  }\n}\n```\n\nFor each variable in the dataset, the 1st and 99th percentile was calculated to address the extreme values, preserving 98% of the data. If a value fell below the 1st percentile, it was capped to the 1st percentile value, furthermore, if a value fell above the 99th percentile, it was capped to the 99th percentile value.\n\nIn addition, outlier handling was intentionally done after imputation, in the event that MICE generated a value that fell outside of the realistic range of values in the original dataset, considering that data cleaning had already taken place.\n\nFurthermore, it was seen that the need to cap outliers was needed as multiple variables had around \\~1% of its data capped, which shows that the data contained extreme values either in the original dataset or from imputation.\n\n### Correlation\n\nA correlation analysis was performed to examine the patterns in the variables and assess potential multicollinearity effects.\n\n```{r}\n\n# Use imputed data (no missing values)\n\ncorr_data <- data_imputed2  \n\ncorr_matrix <- cor(corr_data, use = \"complete.obs\")\n\n# Correlation with FAH\n# fah_corr <- corr_matrix[,\"FAH\"] %>%\n#   as.data.frame() %>%\n#   rownames_to_column(\"Variable\") %>%\n#   rename(Correlation = \".\") %>%\n#   filter(Variable != \"FAH\") %>%\n#   arrange(desc(abs(Correlation)))\n\n# Top 10 correlations with FAH\n# print(head(fah_corr, 10))\n\n# Correlation heatmap\ncorrplot(corr_matrix, method = \"color\", type = \"upper\", \n         order = \"hclust\", tl.cex = 0.7, tl.col = \"black\")\n\n```\n\nIt can be seen from the figure above that correlation between variables exist as the dark blue squares represent strong positive correlations and the dark red squares represent strong negative correlations. The variables from predictor set 1 are represented by dark blue squares, indicating strong positive correlations between the variables. Moreover, FAH has moderate correlations with the variables as the colour range are in the lighter section of the colour scale.\n\nFurthermore, it is important to note that the white squares represent independent variables (correlation of 0), and it can be seen that there are multiple variables such as Aspect_cos and Area have white squares which indicates that multicollinearity is not excessive.\n\nLastly, it can be seen that variables with similar correlation patterns have grouped together creating visible blocks of related variables, which confirms the predictor set groupings capture different types of information.\n\n```{r}\n\n# # FAH Correlation\n# \n# data_imputed2$FAH_factor <- factor(data_imputed2$FAH,\n#                            levels = 0:4,\n#                            labels = c(\"Low\", \"Moderate\", \"Considerable -\", \n#                                      \"Considerable +\", \"High\"))\n# \n# # Predictor 1\n# \n# predictor_1 <- pred_1[pred_1 %in% names(data_imputed2)]\n# \n# data1 <- data_imputed2 %>%\n#   select(FAH_factor, FAH, all_of(predictor_1))\n# \n# corr1 <- cor(data1[,predictor_1], data1$FAH) %>%\n#   as.data.frame() %>%\n#   rownames_to_column(\"Variable\") %>%\n#   rename(FAH_Correlation = \"V1\") %>%\n#   arrange(desc(abs(FAH_Correlation)))\n# \n# # Create boxplots\n# plot1 <- list()\n# for(i in 1:min(4, length(predictor_1))) {\n#   var <- predictor_1[i]\n#   plot1[[i]] <- ggplot(data1, aes(x = factor(FAH_factor), y = .data[[var]])) +\n#     geom_boxplot(fill = \"darkblue\", alpha = 0.7) +\n#     labs(title = paste(var, \"vs FAH\"),\n#          x = \"FAH\", y = var) +\n#     theme_minimal()\n# }\n# \n# do.call(grid.arrange, c(plot1, ncol = 2))\n# \n# # Predictor 2\n# \n# predictor_2 <- pred_2[pred_2 %in% names(data_imputed2)]\n# \n# data2 <- data_imputed2 %>%\n#   select(FAH_factor, FAH, all_of(predictor_2))\n# \n# corr2 <- cor(data2[,predictor_2], data2$FAH) %>%\n#   as.data.frame() %>%\n#   rownames_to_column(\"Variable\") %>%\n#   rename(FAH_Correlation = \"V1\") %>%\n#   arrange(desc(abs(FAH_Correlation)))\n# \n# plot2 <- list()\n# for(i in 1:min(4, length(predictor_2))) {\n#   var <- predictor_2[i]\n#   plot2[[i]] <- ggplot(data2, aes(x = factor(FAH_factor), y = .data[[var]])) +\n#     geom_boxplot(fill = \"darkgreen\", alpha = 0.7) +\n#     labs(title = paste(var, \"vs FAH\"),\n#          x = \"FAH\", y = var) +\n#     theme_minimal()\n# }\n# \n# do.call(grid.arrange, c(plot2, ncol = 2))\n# \n# # Predictor 3\n# \n# predictor_3 <- pred_3[pred_3 %in% names(data_imputed2)]\n# \n# data3 <- data_imputed2 %>%\n#   select(FAH_factor, FAH, all_of(predictor_3))\n# \n# corr3 <- cor(data3[,predictor_3], data3$FAH) %>%\n#   as.data.frame() %>%\n#   rownames_to_column(\"Variable\") %>%\n#   rename(FAH_Correlation = \"V1\") %>%\n#   arrange(desc(abs(FAH_Correlation)))\n# \n# plot3 <- list()\n# for(i in 1:min(4, length(predictor_3))) {\n#   var <- predictor_3[i]\n#   plot3[[i]] <- ggplot(data3, aes(x = factor(FAH_factor), y = .data[[var]])) +\n#     geom_boxplot(fill = \"darkred\", alpha = 0.7) +\n#     labs(title = paste(var, \"vs FAH\"),\n#          x = \"FAH\", y = var) +\n#     theme_minimal()\n# }\n# \n# do.call(grid.arrange, c(plot3, ncol = 2))\n```\n\n### Scaling\n\nScaling was performed to ensure that variables with different units and scales contributed equally to the model and variables with larger numeric values did not dominate the model.\n\n```{r}\n\nset.seed(12345)\n\ntrain_index <- createDataPartition(data_imputed2$FAH, \n                                   p = 0.7, \n                                   list = FALSE)\n\ntrain_data <- data_imputed2[train_index, ]\ntest_data <- data_imputed2[-train_index, ]\n\n# Standardisation\n\nnumeric_vars <- names(data_imputed2)[sapply(data_imputed2, is.numeric)]\nnumeric_vars <- setdiff(numeric_vars, \"FAH\")\n\npreproc_obj <- preProcess(\n  train_data %>% select(all_of(numeric_vars)),\n  method = c(\"center\", \"scale\")  \n)\n\ntrain_scaled <- predict(preproc_obj, train_data)\ntest_scaled <- predict(preproc_obj, test_data)\n\n```\n\nThe data was split using a 70/30 split, which was stratified using FAH to ensure that both the training and testing sets follow a similar distribution of the target variable, FAH. Thereafter, the numeric values from the training dataset were used to calculate the mean and standard deviation of each variable using the preProcess() function and was then applied to both the training and test sets using the predict() function. Furthermore, this approach prevents data leakage which occurs when information from the test set goes into the training set.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":false,"output-file":"final_eda.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","theme":"journal","smooth-scroll":true,"anchor-sections":true,"title":"Final EDA","editor":"visual"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}